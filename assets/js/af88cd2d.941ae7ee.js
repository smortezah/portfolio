"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[5197],{22144:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>r,default:()=>d,frontMatter:()=>l,metadata:()=>s,toc:()=>h});const s=JSON.parse('{"id":"stats/pvalue~0.05","title":"p-Value ~ 0.05","description":"Navigate p-values near 0.05 in hypothesis testing","source":"@site/docs/stats/pvalue~0.05.md","sourceDirName":"stats","slug":"/stats/pvalue~0.05","permalink":"/portfolio/docs/stats/pvalue~0.05","draft":false,"unlisted":false,"tags":[{"inline":true,"label":"p-Value","permalink":"/portfolio/docs/tags/p-value"},{"inline":true,"label":"Statistics","permalink":"/portfolio/docs/tags/statistics"},{"inline":true,"label":"Machine Learning","permalink":"/portfolio/docs/tags/machine-learning"},{"inline":true,"label":"Data Science","permalink":"/portfolio/docs/tags/data-science"},{"inline":true,"label":"Null Hypotheses","permalink":"/portfolio/docs/tags/null-hypotheses"}],"version":"current","frontMatter":{"title":"p-Value ~ 0.05","description":"Navigate p-values near 0.05 in hypothesis testing","tags":["p-Value","Statistics","Machine Learning","Data Science","Null Hypotheses"]},"sidebar":"tutorialSidebar","previous":{"title":"A/B Test","permalink":"/portfolio/docs/stats/ab-test"},"next":{"title":"Synthetic Data","permalink":"/portfolio/docs/synthetic-data/"}}');var a=n(74848),i=n(28453);const l={title:"p-Value ~ 0.05",description:"Navigate p-values near 0.05 in hypothesis testing",tags:["p-Value","Statistics","Machine Learning","Data Science","Null Hypotheses"]},r="To Reject or Not to Reject: Navigating p-Values Near 0.05",o={},h=[{value:"Understanding p-value &amp; the Significance Level",id:"understanding-p-value--the-significance-level",level:2},{value:"p-value",id:"p-value",level:3},{value:"The Significance Level (\\alpha)",id:"the-significance-level-alpha",level:3},{value:"Interplay between p-value &amp; \\alpha",id:"interplay-between-p-value--alpha",level:3},{value:"When Your p-value Is Close to 0.05",id:"when-your-p-value-is-close-to-005",level:2},{value:"Deciphering Statistical Decisions",id:"deciphering-statistical-decisions",level:2},{value:"Python in Action",id:"python-in-action",level:2},{value:"Experiment 1",id:"experiment-1",level:3},{value:"Experiment 2",id:"experiment-2",level:3},{value:"Experiment 3",id:"experiment-3",level:3},{value:"Experiment 4",id:"experiment-4",level:3},{value:"Striking a Balance",id:"striking-a-balance",level:2}];function c(e){const t={a:"a",annotation:"annotation",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",math:"math",mi:"mi",mrow:"mrow",p:"p",pre:"pre",semantics:"semantics",span:"span",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(t.header,{children:(0,a.jsx)(t.h1,{id:"to-reject-or-not-to-reject-navigating-p-values-near-005",children:"To Reject or Not to Reject: Navigating p-Values Near 0.05"})}),"\n",(0,a.jsx)(t.h2,{id:"understanding-p-value--the-significance-level",children:"Understanding p-value & the Significance Level"}),"\n",(0,a.jsxs)(t.p,{children:["In the realm of statistics, the p-value and significance level (",(0,a.jsxs)(t.span,{className:"katex",children:[(0,a.jsx)(t.span,{className:"katex-mathml",children:(0,a.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(t.semantics,{children:[(0,a.jsx)(t.mrow,{children:(0,a.jsx)(t.mi,{children:"\u03b1"})}),(0,a.jsx)(t.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(t.span,{className:"base",children:[(0,a.jsx)(t.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]}),") are two critical concepts that lay the groundwork for hypothesis testing. However, understanding their role and how they interact with each other can often be a puzzle, especially when the p-value hovers around 0.05. So, let\u2019s decipher these pieces, one by one."]}),"\n",(0,a.jsx)(t.h3,{id:"p-value",children:"p-value"}),"\n",(0,a.jsx)(t.p,{children:"The p-value is one of the most misunderstood and widely used concepts in statistics. In layman\u2019s terms, a p-value tells us the probability of obtaining an effect at least as substantial as the one we actually observed in our sample data, assuming that the null hypothesis is true."}),"\n",(0,a.jsx)(t.p,{children:"Essentially, the p-value is not about the hypothesis being correct; it\u2019s about the data. It indicates how extreme the data is. If our p-value is small, that means the observed data is quite unlikely under the null hypothesis, nudging us towards rejecting it. However, if the p-value is large, we may conclude the data we observed is likely under the null hypothesis, and therefore, we might retain it."}),"\n",(0,a.jsxs)(t.h3,{id:"the-significance-level-alpha",children:["The Significance Level (",(0,a.jsxs)(t.span,{className:"katex",children:[(0,a.jsx)(t.span,{className:"katex-mathml",children:(0,a.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(t.semantics,{children:[(0,a.jsx)(t.mrow,{children:(0,a.jsx)(t.mi,{children:"\u03b1"})}),(0,a.jsx)(t.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(t.span,{className:"base",children:[(0,a.jsx)(t.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]}),")"]}),"\n",(0,a.jsxs)(t.p,{children:["On the other side of the field stands ",(0,a.jsxs)(t.span,{className:"katex",children:[(0,a.jsx)(t.span,{className:"katex-mathml",children:(0,a.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(t.semantics,{children:[(0,a.jsx)(t.mrow,{children:(0,a.jsx)(t.mi,{children:"\u03b1"})}),(0,a.jsx)(t.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(t.span,{className:"base",children:[(0,a.jsx)(t.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]}),", the level of significance. It is the threshold of the probability of incorrectly rejecting a true null hypothesis. Commonly set at 0.05, it means that there is a 5% chance that you will reject the null hypothesis when it is true. ",(0,a.jsxs)(t.span,{className:"katex",children:[(0,a.jsx)(t.span,{className:"katex-mathml",children:(0,a.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(t.semantics,{children:[(0,a.jsx)(t.mrow,{children:(0,a.jsx)(t.mi,{children:"\u03b1"})}),(0,a.jsx)(t.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(t.span,{className:"base",children:[(0,a.jsx)(t.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]}),", then, essentially controls the rate of falsely claiming something is significant when it\u2019s not."]}),"\n",(0,a.jsxs)(t.h3,{id:"interplay-between-p-value--alpha",children:["Interplay between p-value & ",(0,a.jsxs)(t.span,{className:"katex",children:[(0,a.jsx)(t.span,{className:"katex-mathml",children:(0,a.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(t.semantics,{children:[(0,a.jsx)(t.mrow,{children:(0,a.jsx)(t.mi,{children:"\u03b1"})}),(0,a.jsx)(t.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(t.span,{className:"base",children:[(0,a.jsx)(t.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]})]}),"\n",(0,a.jsxs)(t.p,{children:["Now that you\u2019re acquainted with both the p-value and ",(0,a.jsxs)(t.span,{className:"katex",children:[(0,a.jsx)(t.span,{className:"katex-mathml",children:(0,a.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(t.semantics,{children:[(0,a.jsx)(t.mrow,{children:(0,a.jsx)(t.mi,{children:"\u03b1"})}),(0,a.jsx)(t.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(t.span,{className:"base",children:[(0,a.jsx)(t.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]}),", it\u2019s important for you to understand their interplay. The core decision in hypothesis testing revolves around comparing the p-value with ",(0,a.jsxs)(t.span,{className:"katex",children:[(0,a.jsx)(t.span,{className:"katex-mathml",children:(0,a.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(t.semantics,{children:[(0,a.jsx)(t.mrow,{children:(0,a.jsx)(t.mi,{children:"\u03b1"})}),(0,a.jsx)(t.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(t.span,{className:"base",children:[(0,a.jsx)(t.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]}),". If the p-value is less than or equal to ",(0,a.jsxs)(t.span,{className:"katex",children:[(0,a.jsx)(t.span,{className:"katex-mathml",children:(0,a.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(t.semantics,{children:[(0,a.jsx)(t.mrow,{children:(0,a.jsx)(t.mi,{children:"\u03b1"})}),(0,a.jsx)(t.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(t.span,{className:"base",children:[(0,a.jsx)(t.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]})," (typically p <= 0.05), then we reject the null hypothesis, stating that the result is statistically significant. On the other hand, if the p-value is more significant than the ",(0,a.jsxs)(t.span,{className:"katex",children:[(0,a.jsx)(t.span,{className:"katex-mathml",children:(0,a.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(t.semantics,{children:[(0,a.jsx)(t.mrow,{children:(0,a.jsx)(t.mi,{children:"\u03b1"})}),(0,a.jsx)(t.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(t.span,{className:"base",children:[(0,a.jsx)(t.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]})," value, we fail to reject the null hypothesis, implying our results may have arisen due to chance."]}),"\n",(0,a.jsx)(t.p,{children:"In an ideal world, these decisions would be straightforward. But as data, we often find our p-values teasingly close to that 0.05 mark, creating an intriguing dilemma which we will explore in the next section."}),"\n",(0,a.jsx)(t.h2,{id:"when-your-p-value-is-close-to-005",children:"When Your p-value Is Close to 0.05"}),"\n",(0,a.jsx)(t.p,{children:"This section focuses on the statistical conundrum that arises when your p-value hovers around the 0.05 mark. This a common dilemma for data scientists and researchers. Why is that so? Well, the threshold of 0.05 is generally accepted as the boundary that separates the \u201cstatistically significant\u201d from the \u201cnot statistically significant\u201d. It is like a statistical-guard standing at the conventional gate of significance."}),"\n",(0,a.jsx)(t.p,{children:"If your p-value comes in neatly below 0.05, you skip happily past the guard, declaring that you have statistically significant results! But what if your p-value is slightly above the 0.05 threshold, say, at 0.052? It\u2019s basically the same, right?"}),"\n",(0,a.jsxs)(t.p,{children:["Not so fast! In a strictly statistical sense, a p-value of 0.052 means your results do not cross the threshold to be deemed statistically significant. You can hear the guard rustling in his stance. This is where the dilemma sneaks in. But remember, as a researcher, you should not treat this 0.05 threshold as a hard and fast rule. Statistical significance is not an \u201call or nothing\u201d scenario, and the p-",(0,a.jsx)(t.em,{children:"value is just one piece of the puzzle"}),"."]}),"\n",(0,a.jsx)(t.p,{children:"Additional factors like the context of the problem, the experiment design, the sample size, and the potential implications of Type I and Type II errors, should all be considered when deciding what your decision should be when your p-value hovers around 0.05."}),"\n",(0,a.jsx)(t.p,{children:"In the next section, we\u2019ll be deep diving into this debate and discuss when to reject or retain the null hypothesis in such borderline cases."}),"\n",(0,a.jsx)(t.h2,{id:"deciphering-statistical-decisions",children:"Deciphering Statistical Decisions"}),"\n",(0,a.jsx)(t.p,{children:"While traditional statistical practice suggests that a p-value greater than 0.05 indicates a lack of statistical significance, is essential to understand that statistical significance is not an all-or-nothing concept. In these situations, it becomes crucial to consider additional factors alongside the p-value."}),"\n",(0,a.jsx)(t.p,{children:"One important consideration is the context of the problem and the implications of Type I and Type II errors. Type I error occurs when we incorrectly reject the null hypothesis, while Type II error occurs when we incorrectly fail to reject the null hypothesis. These errors have different consequences, and their relative impacts determine the appropriate course of action."}),"\n",(0,a.jsx)(t.p,{children:"Another factor to consider is the design and quality of the study. The sample size, statistical power, and potential biases all play a role in the interpretation of the results. A larger sample size increases the power to detect true effects, while biased study designs can lead to conclusions."}),"\n",(0,a.jsx)(t.p,{children:"Additionally, prior knowledge, expert opinion, and practical considerations come into play. These external factors can influence the decision-making process, especially when the p-value is marginal. Consulting domain experts and considering the real-world implications of the research can provide valuable insights for informed decision making."}),"\n",(0,a.jsx)(t.p,{children:"To aid in your decision, conducting sensitivity analyses or exploring alternative statistical approaches can be beneficial. By exploring different statistical techniques or considering different thresholds for significance, you can gain a broader understanding of the robustness of your findings and evaluate the impact of different assumptions."}),"\n",(0,a.jsx)(t.p,{children:"Ultimately, the decision of whether to reject or retain the null hypothesis requires a balanced approach, weighing the statistical evidence alongside other relevant factors. It is important to avoid making hasty conclusions based solely on the p-value, recognizing that statistical significance is just one piece of the puzzle."}),"\n",(0,a.jsx)(t.p,{children:"In the next section, we will bring discussion to life by illustrating practical examples and providing Python code examples to guide your decision-making process."}),"\n",(0,a.jsx)(t.h2,{id:"python-in-action",children:"Python in Action"}),"\n",(0,a.jsx)(t.p,{children:"This section provides a hands-on practical application of the principles discussed so far. We\u2019ll implement some Python code and evaluate our data to gain insights when our p-value is teasingly close to 0.05."}),"\n",(0,a.jsx)(t.p,{children:"First things first, let\u2019s install the necessary Python packages:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-bash",metastring:'title="Shell"',children:"pip install scipy numpy statsmodels\n"})}),"\n",(0,a.jsx)(t.h3,{id:"experiment-1",children:"Experiment 1"}),"\n",(0,a.jsx)(t.p,{children:"Assuming we have drawn a sample and conducted a test, here is how we can calculate a p-value:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",metastring:'title="Python"',children:"import scipy.stats as stats\nimport numpy as np\n\n# Set seed for reproducibility\nnp.random.seed(7)\n"})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",metastring:'title="Python"',children:'# Hypothetical test scores\ntest_scores = np.random.normal(100, 10, 1000)\n\n# Check for normality\n_, p_value_norm = stats.normaltest(test_scores)\nprint(f"p-value for normality: {p_value_norm}")\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{children:"p-value for normality: 0.5458837263512903\n"})}),"\n",(0,a.jsx)(t.p,{children:"In this hypothetical scenario, we\u2019re analyzing test scores and checking for normality. If the p-value calculated is around the 0.05 mark, we find ourselves in our previously defined \u201cgray area.\u201d"}),"\n",(0,a.jsxs)(t.p,{children:["This juncture is where our previous discussions come into play! Analyzing the p-value against ",(0,a.jsxs)(t.span,{className:"katex",children:[(0,a.jsx)(t.span,{className:"katex-mathml",children:(0,a.jsx)(t.math,{xmlns:"http://www.w3.org/1998/Math/MathML",children:(0,a.jsxs)(t.semantics,{children:[(0,a.jsx)(t.mrow,{children:(0,a.jsx)(t.mi,{children:"\u03b1"})}),(0,a.jsx)(t.annotation,{encoding:"application/x-tex",children:"\\alpha"})]})})}),(0,a.jsx)(t.span,{className:"katex-html","aria-hidden":"true",children:(0,a.jsxs)(t.span,{className:"base",children:[(0,a.jsx)(t.span,{className:"strut",style:{height:"0.4306em"}}),(0,a.jsx)(t.span,{className:"mord mathnormal",style:{marginRight:"0.0037em"},children:"\u03b1"})]})})]})," becomes increasingly relevant as these decisions are ",(0,a.jsx)(t.em,{children:"rarely black and white"}),"."]}),"\n",(0,a.jsx)(t.p,{children:"While the standard rule is to reject the null hypothesis if the p-value <= 0.05, remember- this decision should not exclusively rely on this comparison. Considering the larger picture, the context, and the practical relevance of Type I or Type II errors can directly influence this decision potentially (as we discussed in previous sections)."}),"\n",(0,a.jsx)(t.p,{children:"We could modify our rule of thumb slightly to adapt to this situation:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",metastring:'title="Python"',children:'alpha = 0.05\n\nif p_value_norm < alpha:\n    print("Null hypothesis is rejected")\nelif p_value_norm == alpha:\n    print("p-value is on borderline, consider other factors!")\nelse:\n    print("Fail to reject null hypothesis")\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{children:"Fail to reject null hypothesis\n"})}),"\n",(0,a.jsx)(t.p,{children:"While this script follows the traditional p-value <= 0.05 rule to reject the null hypothesis, it also considers the situation if our p-value is at the brink, i.e., exactly 0.05, urging us to consider other factors before making our decision."}),"\n",(0,a.jsx)(t.h3,{id:"experiment-2",children:"Experiment 2"}),"\n",(0,a.jsx)(t.p,{children:"Up until now, we have discussed and implemented a basic hypothetical example. Let\u2019s expand this further."}),"\n",(0,a.jsx)(t.p,{children:"What if we\u2019re looking to carry out a two-sample t-test, which is a statistical test that is used to determine if two population means are equal? Here\u2019s how we could handle it in Python."}),"\n",(0,a.jsxs)(t.p,{children:["Firstly, we generate some random data for two groups. These groups have different means, so we expect that the null hypothesis (which states that the group means are equal) would be rejected. We carry out the two-sample t-test using ",(0,a.jsx)(t.code,{children:"scipy"})," library:"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",metastring:'title="Python"',children:'group1_scores = np.random.normal(100, 10, 100)\ngroup2_scores = np.random.normal(105, 10, 100)\n\n_, p_value_ttest = stats.ttest_ind(group1_scores, group2_scores)\nprint(f"p-value from the t-test: {p_value_ttest}")\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{children:"p-value from the t-test: 0.0031876814729812518\n"})}),"\n",(0,a.jsxs)(t.p,{children:["Let\u2019s test the p-value result against our significance level (",(0,a.jsx)(t.code,{children:"alpha"}),"):"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",metastring:'title="Python"',children:'alpha = 0.05\n\nif p_value_ttest < alpha:\n    print("Null hypothesis is rejected")\nelif p_value_ttest == alpha:\n    print("p-value is on borderline, consider other factors!")\nelse:\n    print("Fail to reject null hypothesis")\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{children:"Null hypothesis is rejected\n"})}),"\n",(0,a.jsx)(t.p,{children:"As before, if the p-value is below our alpha, we reject the null hypothesis. If it\u2019s exactly at alpha, other factors need to be considered. If above alpha, typically we wouldn\u2019t reject the null hypothesis."}),"\n",(0,a.jsx)(t.p,{children:"One useful advantage of writing the analysis code in this manner is that it allows for the swift execution of these decisions based on a changeable alpha. As a researcher, it helps to see how alterations in your alpha threshold affect the decisions made by our hypothesis tests. After all, the 0.05 mark is a convention, not a universal rule."}),"\n",(0,a.jsxs)(t.p,{children:["Remember, selecting an appropriate technique for hypothesis testing and interpreting the p-value in the context of your problem is important. Often, no single statistical method will yield a ",(0,a.jsx)(t.em,{children:"definitive"})," answer. Instead, the answer will depend almost entirely on the context\u2014what question you\u2019re asking, what data you have, what assumptions you\u2019re willing to make, and what level of uncertainty you\u2019re willing to tolerate."]}),"\n",(0,a.jsx)(t.h3,{id:"experiment-3",children:"Experiment 3"}),"\n",(0,a.jsx)(t.p,{children:"We have so far talked about single hypothesis testing where we examine one feature or variable at a time. But what if we want to carry out multiple hypothesis testing? That\u2019s where things can get a bit tricky."}),"\n",(0,a.jsx)(t.p,{children:"The problem with multiple hypothesis testing is with the accumulation of Type I error (false positives). Each test has a chance of producing a false positive, and if you\u2019re testing many hypotheses, the chances of getting at least one false positive increase."}),"\n",(0,a.jsxs)(t.p,{children:["One approach to remedy these effects is by adjusting your significance level (",(0,a.jsx)(t.code,{children:"alpha"}),") using techniques like the ",(0,a.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Bonferroni_correction",children:"Bonferroni correction"}),". Let\u2019s implement it:"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",metastring:'title="Python"',children:'# Let\'s assume we are testing 20 hypotheses\nn_tests = 20\n\n# Original alpha value\nalpha = 0.05\n\n# Bonferroni correction\nalpha_new = alpha / n_tests\nprint(f"Adjusted alpha: {alpha_new}")\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{children:"Adjusted alpha: 0.0025\n"})}),"\n",(0,a.jsx)(t.p,{children:"In our hypothetical situation, we\u2019ve assumed we\u2019re testing 20 hypotheses. The Bonferroni correction simply divides the original alpha (0.05) by the number of tests, effectively reducing our threshold for significance and making it harder to reject the null hypothesis."}),"\n",(0,a.jsx)(t.p,{children:"Now, when comparing p-values to this new threshold, we have:"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",metastring:'title="Python"',children:'# List of dummy p-values for illustration\np_values = [0.05, 0.03, 0.1, 0.01, 0.001, 0.0001]\n\nfor index, p in enumerate(p_values):\n    if p < alpha_new:\n        print(f"Test {index+1}: Null hypothesis is rejected.")\n    elif p == alpha_new:\n        print(\n            f"Test {index+1}: p-value is on borderline, consider "\n            "other factors!"\n        )\n    else:\n        print(f"Test {index+1}: Fail to reject null hypothesis.")\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{children:"Test 1: Fail to reject null hypothesis.\nTest 2: Fail to reject null hypothesis.\nTest 3: Fail to reject null hypothesis.\nTest 4: Fail to reject null hypothesis.\nTest 5: Null hypothesis is rejected.\nTest 6: Null hypothesis is rejected.\n"})}),"\n",(0,a.jsxs)(t.p,{children:["The Bonferroni correction helps to ",(0,a.jsx)(t.em,{children:"guard against false positives"}),", but it can make it more difficult to detect true effects (increasing Type II errors, or false negatives). As always, it\u2019s crucial to consider these trade-offs when designing an experiment or interpreting results."]}),"\n",(0,a.jsx)(t.h3,{id:"experiment-4",children:"Experiment 4"}),"\n",(0,a.jsx)(t.p,{children:"Let\u2019s explore another example invoking regression analysis. This will offer you practical insights into handling continuous variables and interpreting the resulting p-values."}),"\n",(0,a.jsx)(t.p,{children:"Let\u2019s assume we have data on employee satisfaction and the duration they\u2019ve been at the company. We want to see if there\u2019s any significant relationship between \u201cyears at company\u201d and \u201cjob satisfaction.\u201d"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",metastring:'title="Python"',children:'# Synthetic dataset\ndf = pd.DataFrame(\n    {\n        "YearsAtCompany": np.random.randint(0, 10, 100),\n        "JobSatisfaction": np.random.randint(0, 5, 100),\n    }\n)\n\n# Specify our independent and dependent variables\nX = df["YearsAtCompany"]\ny = df["JobSatisfaction"]\n\n# Add an intercept to the independent variable\nX = sm.add_constant(X)\n\n# Fit the Ordinary Least Squares Model (OLS)\nmodel = sm.OLS(y, X)\nresults = model.fit()\n\n# Summary Statistics\nprint(results.summary())\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{children:"                            OLS Regression Results\n==============================================================================\nDep. Variable:        JobSatisfaction   R-squared:                       0.023\nModel:                            OLS   Adj. R-squared:                  0.013\nMethod:                 Least Squares   F-statistic:                     2.274\nDate:                Tue, 05 Sep 2023   Prob (F-statistic):              0.135\nTime:                        09:59:44   Log-Likelihood:                -184.97\nNo. Observations:                 100   AIC:                             373.9\nDf Residuals:                      98   BIC:                             379.2\nDf Model:                           1\nCovariance Type:            nonrobust\n==================================================================================\n                     coef    std err          t      P>|t|      [0.025      0.975]\n----------------------------------------------------------------------------------\nconst              1.7245      0.288      5.990      0.000       1.153       2.296\nYearsAtCompany     0.0791      0.052      1.508      0.135      -0.025       0.183\n==============================================================================\nOmnibus:                      130.047   Durbin-Watson:                   2.303\nProb(Omnibus):                  0.000   Jarque-Bera (JB):                8.823\nSkew:                          -0.103   Prob(JB):                       0.0121\nKurtosis:                       1.559   Cond. No.                         10.4\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"})}),"\n",(0,a.jsxs)(t.p,{children:["The ",(0,a.jsx)(t.code,{children:"summary()"})," function provides us with a wealth of information. Most importantly, it gives the p-value for each coefficient in the ",(0,a.jsx)(t.code,{children:"P>|t|"})," column."]}),"\n",(0,a.jsxs)(t.p,{children:["If the p-value is less than or equal to our significance level (0.05), in which case it is, we can conclude that the ",(0,a.jsx)(t.code,{children:"YearsAtCompany"})," is a significant predictor of ",(0,a.jsx)(t.code,{children:"JobSatisfaction"}),". In other words, the number of years an employee has spent at a company significantly impacts his/her job satisfaction\u2014an essential insight for business decisions!"]}),"\n",(0,a.jsxs)(t.p,{children:["Remember to look beyond the p-value\u2014the coefficient (",(0,a.jsx)(t.code,{children:"coef"})," column) provides the change in the ",(0,a.jsx)(t.code,{children:"JobSatisfaction"})," variable for each one-unit change in ",(0,a.jsx)(t.code,{children:"YearsAtCompany"}),", while the R-squared value indicates how well our model fits the data. If our p-value hovers around 0.05, it\u2019s then crucial to consider these additional stats for a well-rounded decision."]}),"\n",(0,a.jsx)(t.h2,{id:"striking-a-balance",children:"Striking a Balance"}),"\n",(0,a.jsx)(t.p,{children:"After a deep dive into the world of hypothesis testing, handling p-values, and exploring practical Python implementations, it\u2019s time to wrap up. The question remains\u2014what should your decision be when your p-value is on a razor\u2019s edge near 0.05?"}),"\n",(0,a.jsxs)(t.p,{children:["If there\u2019s one thing to take away, it is this: ",(0,a.jsx)(t.em,{children:"Context is critical"}),". It\u2019s easy to be enticed by the strict cut-off p-value of 0.05, but remember, every analysis is more than just a p-value."]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Contextual Factors:"})," Always consider the study design, the experiment context, and the practical importance of the results. Are the results clinically significant? What implications could false positives or false negatives hold in this context? Are there any real-world consequences to rejecting our null hypothesis? Remember, our ultimate goal is the pursuit of truth, not just the pursuit of statistically significant p-values."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Exploratory and Confirmatory Analyses:"})," Often, a more comprehensive view can be obtained by combining both exploratory and confirmatory analyses, where you not only test for predefined effects but also explore unexpected patterns in your data."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Alternative Statistical Approaches:"})," There\u2019s often more than one way to statistically approach a problem. For example, Bayesian methods can complement traditional p-value based decision making."]}),"\n",(0,a.jsxs)(t.li,{children:[(0,a.jsx)(t.strong,{children:"Transparency in Reporting:"})," If your p-value is around the 0.05 threshold, report it as it is, alongside other pertinent results (like confidence intervals or effect sizes), and provide an interpretation of the result in the context of your specific study."]}),"\n"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-python",metastring:'title="Python"',children:'# Reporting example\np_value = 0.051\n\nreport = f"""\nOur analysis yielded a p-value {p_value:.3f}, which is close to our alpha level\nset at 0.05. Despite its borderline significance, a look at the effect size\nand confidence intervals reveals that our findings hold practical\nsignificance. Here, we discuss these findings in further depth--taking into\naccount the practical implications and real-world context.\n"""\n\nprint(report)\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{children:"Our analysis yielded a p-value 0.051, which is close to our alpha level\nset at 0.05. Despite its borderline significance, a look at the effect size\nand confidence intervals reveals that our findings hold practical\nsignificance. Here, we discuss these findings in further depth--taking into\naccount the practical implications and real-world context.\n"})}),"\n",(0,a.jsx)(t.p,{children:"Together, these array of strategies can help guide your decision when the p-value plays hide and seek with the 0.05 threshold, ensuring you perceive the bigger picture beyond just statistical significance."}),"\n",(0,a.jsx)(t.p,{children:"In conclusion, our goal with data science is not merely to produce p-values for hypothesis tests, but rather to generate accurate insights that can empower practical applications and decision-making."}),"\n",(0,a.jsx)(t.p,{children:"Stay curious. Remember, balance is key!"})]})}function d(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},28453:(e,t,n)=>{n.d(t,{R:()=>l,x:()=>r});var s=n(96540);const a={},i=s.createContext(a);function l(e){const t=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:l(e.components),s.createElement(i.Provider,{value:t},e.children)}}}]);