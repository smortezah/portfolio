"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[5730],{22104:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var t=a(85893),i=a(11151);const s={title:"Polars",tags:["Polars","Data Science","Dataframes","Fast","Python"]},l="Data Mastery: Polars Unpacked",r={id:"eda/polars",title:"Polars",description:"Introduction",source:"@site/docs/eda/polars.md",sourceDirName:"eda",slug:"/eda/polars",permalink:"/portfolio/docs/eda/polars",draft:!1,unlisted:!1,tags:[{label:"Polars",permalink:"/portfolio/docs/tags/polars"},{label:"Data Science",permalink:"/portfolio/docs/tags/data-science"},{label:"Dataframes",permalink:"/portfolio/docs/tags/dataframes"},{label:"Fast",permalink:"/portfolio/docs/tags/fast"},{label:"Python",permalink:"/portfolio/docs/tags/python"}],version:"current",frontMatter:{title:"Polars",tags:["Polars","Data Science","Dataframes","Fast","Python"]},sidebar:"tutorialSidebar",previous:{title:"Dealing with Missing Data",permalink:"/portfolio/docs/eda/missing-data"},next:{title:"Extract, Transform, Load",permalink:"/portfolio/docs/etl/"}},o={},d=[{value:"Introduction",id:"introduction",level:2},{value:"Setting Up Your Environment",id:"setting-up-your-environment",level:2},{value:"Loading and Inspecting Your Data",id:"loading-and-inspecting-your-data",level:2},{value:"Creating a Synthetic Dataset",id:"creating-a-synthetic-dataset",level:3},{value:"Inspecting Your Data",id:"inspecting-your-data",level:3},{value:"Data Cleaning and Preprocessing",id:"data-cleaning-and-preprocessing",level:2},{value:"Missing Values",id:"missing-values",level:3},{value:"Data Type Conversion",id:"data-type-conversion",level:3},{value:"Creating New Columns",id:"creating-new-columns",level:3},{value:"Removing Duplicates",id:"removing-duplicates",level:3},{value:"Data Visualization",id:"data-visualization",level:2},{value:"Histogram",id:"histogram",level:3},{value:"Box Plot",id:"box-plot",level:3},{value:"Scatter Plot",id:"scatter-plot",level:3},{value:"Bar Chart",id:"bar-chart",level:3},{value:"Descriptive Statistics and Insights",id:"descriptive-statistics-and-insights",level:2},{value:"Mean",id:"mean",level:3},{value:"Median",id:"median",level:3},{value:"Standard Deviation",id:"standard-deviation",level:3},{value:"Correlation",id:"correlation",level:3},{value:"Advanced EDA Techniques",id:"advanced-eda-techniques",level:2},{value:"Grouping Data",id:"grouping-data",level:3},{value:"Apply Custom Functions",id:"apply-custom-functions",level:3},{value:"Pivot Tables",id:"pivot-tables",level:3},{value:"Conclusion and Next Steps",id:"conclusion-and-next-steps",level:2}];function c(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"data-mastery-polars-unpacked",children:"Data Mastery: Polars Unpacked"}),"\n",(0,t.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsxs)(n.p,{children:["Welcome to the realm of ",(0,t.jsx)(n.a,{href:"https://www.pola.rs/",children:"Polars"}),"\u2014a fast DataFrame library in Python designed for large datasets. Inspired by pandas, Polars takes it up a notch by offering a more memory-efficient and faster performance, thanks to its implementation in the Rust programming language."]}),"\n",(0,t.jsxs)(n.p,{children:["Polars can handle large datasets effortlessly and delivers computations at a lightning-fast speed without the need to load everything in memory. Plus, leveraging ",(0,t.jsx)(n.a,{href:"https://arrow.apache.org/",children:"Apache Arrow"})," to execute vectorized operations gives it an extra edge for high performance."]}),"\n",(0,t.jsx)(n.p,{children:"Apart from its performance prowess, Polars boasts an intuitive API that aligns closely with what you\u2019re familiar within pandas, promising an easy transition."}),"\n",(0,t.jsx)(n.p,{children:"This article will take you on a journey to unlock the full potential of Polars through a hands-on tutorial on Exploratory Data Analysis. Let\u2019s begin!"}),"\n",(0,t.jsx)(n.h2,{id:"setting-up-your-environment",children:"Setting Up Your Environment"}),"\n",(0,t.jsx)(n.p,{children:"First off, you need a Python environment (version 3.7 or above) and pip (the Python package installer)."}),"\n",(0,t.jsx)(n.p,{children:"Installing Polars is as simple as typing out this command in your terminal:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:'title="Shell"',children:"pip install polars\n"})}),"\n",(0,t.jsx)(n.p,{children:"To verify whether the installation was successful, execute the following:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:"import polars as pl\n\nprint(pl.__version__)\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"'0.19.3'\n"})}),"\n",(0,t.jsx)(n.p,{children:"The full setup for this tutorial is as the following:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:'title="Shell"',children:"pip install polars matplotlib\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'import random\nimport string\n\nimport matplotlib.pyplot as plt\n\nimport polars as pl\n\n\nSEED = 777  # for reproducibility\nplt.style.use("ggplot_classic.mplstyle")  # a custom plot style\n'})}),"\n",(0,t.jsx)(n.p,{children:"No error? You\u2019re ready to take advantage of the speedy and efficient data analysis capabilities of Polars."}),"\n",(0,t.jsx)(n.p,{children:"In the next section, we\u2019ll dive into loading and inspecting data. Stay tuned!"}),"\n",(0,t.jsx)(n.h2,{id:"loading-and-inspecting-your-data",children:"Loading and Inspecting Your Data"}),"\n",(0,t.jsx)(n.p,{children:"Polars flexes its muscles when dealing with sizable data. For the purposes of this tutorial, since we want to focus on Polars and its features rather than get lost in the complexities of data, let\u2019s create our own synthetic dataset of 1,000,000 records. This dataset will stimulate the challenges of dealing with large data in a controlled fashion."}),"\n",(0,t.jsx)(n.h3,{id:"creating-a-synthetic-dataset",children:"Creating a Synthetic Dataset"}),"\n",(0,t.jsx)(n.p,{children:"Creating synthetic dataset helps us simulate real-world scenarios in a manageable and controlled manner. Here\u2019s how you can create a synthetic dataset of 1,000,000 records using Polars:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'# Defining the size of our dataset\nsize = 1000000\n\n# Setting the seed for reproducibility\nrandom.seed(SEED)\n\n# Creating a DataFrame\nage = random.choices(range(20, 40), k=size // 2) + random.choices(\n    range(40, 71), k=size - size // 2\n)\ncity = random.choices(\n    ["New York", "London", "Paris", "Tokyo"],\n    weights=[1.0, 0.9, 0.3, 1.5],\n    k=size,\n)\nis_married = random.choices([True, False], weights=[1.0, 1.5], k=size)\nbmi = [round(random.uniform(17.0, 27.0), 2) for _ in range(size)]\n\ndf = pl.DataFrame(\n    {"age": age, "city": city, "is_married": is_married, "bmi": bmi}\n)\n'})}),"\n",(0,t.jsxs)(n.p,{children:["This code will generate a synthetic dataset, ",(0,t.jsx)(n.code,{children:"df"}),", consisting of four variables ",(0,t.jsx)(n.code,{children:"age"}),", ",(0,t.jsx)(n.code,{children:"city"}),", ",(0,t.jsx)(n.code,{children:"is_married"}),", and ",(0,t.jsx)(n.code,{children:"bmi"}),", each with 1,000,000 records. ",(0,t.jsx)(n.code,{children:"pl.DataFrame"})," is used to create a DataFrame, same as we do in pandas, only much faster with larger datasets!"]}),"\n",(0,t.jsx)(n.h3,{id:"inspecting-your-data",children:"Inspecting Your Data"}),"\n",(0,t.jsx)(n.p,{children:"Once our dataset is ready, it\u2019s time to take a glimpse at our data. Polars supports similar functions to pandas for displaying and summarizing the data:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Head of the DataFrame:"})," View the first few records of DataFrame:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:"df.head()\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 age \u2506 city     \u2506 is_married \u2506 bmi   \u2502\n\u2502 --- \u2506 ---      \u2506 ---        \u2506 ---   \u2502\n\u2502 i64 \u2506 str      \u2506 bool       \u2506 f64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 24  \u2506 New York \u2506 true       \u2506 21.84 \u2502\n\u2502 28  \u2506 Tokyo    \u2506 false      \u2506 24.37 \u2502\n\u2502 27  \u2506 Tokyo    \u2506 false      \u2506 20.84 \u2502\n\u2502 25  \u2506 London   \u2506 true       \u2506 24.02 \u2502\n\u2502 26  \u2506 Paris    \u2506 true       \u2506 25.41 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Summary Statistics:"})," Get a quick statistical overview of your data:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:"df.describe()\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"shape: (9, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 describe   \u2506 age       \u2506 city    \u2506 is_married \u2506 bmi       \u2502\n\u2502 ---        \u2506 ---       \u2506 ---     \u2506 ---        \u2506 ---       \u2502\n\u2502 str        \u2506 f64       \u2506 str     \u2506 f64        \u2506 f64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 count      \u2506 1e6       \u2506 1000000 \u2506 1e6        \u2506 1e6       \u2502\n\u2502 null_count \u2506 0.0       \u2506 0       \u2506 0.0        \u2506 0.0       \u2502\n\u2502 mean       \u2506 42.258076 \u2506 null    \u2506 0.399538   \u2506 21.998547 \u2502\n\u2502 std        \u2506 14.804733 \u2506 null    \u2506 0.489804   \u2506 2.88818   \u2502\n\u2502 min        \u2506 20.0      \u2506 London  \u2506 0.0        \u2506 17.0      \u2502\n\u2502 25%        \u2506 30.0      \u2506 null    \u2506 null       \u2506 19.5      \u2502\n\u2502 50%        \u2506 40.0      \u2506 null    \u2506 null       \u2506 22.0      \u2502\n\u2502 75%        \u2506 55.0      \u2506 null    \u2506 null       \u2506 24.5      \u2502\n\u2502 max        \u2506 70.0      \u2506 Tokyo   \u2506 1.0        \u2506 27.0      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"With Polars, loading and inspecting data is as easy and intuitive as it has been with pandas, only more efficient with larger datasets."}),"\n",(0,t.jsx)(n.p,{children:"In the next section, we will dive into data cleaning. Stay tuned!"}),"\n",(0,t.jsx)(n.h2,{id:"data-cleaning-and-preprocessing",children:"Data Cleaning and Preprocessing"}),"\n",(0,t.jsxs)(n.p,{children:["Data in the real world is famously ",(0,t.jsx)(n.em,{children:"messy"}),". From mistyped entries and missing values to duplicates that could skew our analysis, we need to employ various strategies data cleaning and preprocessing before our data is ready for analysis."]}),"\n",(0,t.jsx)(n.h3,{id:"missing-values",children:"Missing Values"}),"\n",(0,t.jsx)(n.p,{children:"Missing data is a common problem in real-world data sets, let\u2019s create some missing data and then manage them."}),"\n",(0,t.jsx)(n.p,{children:"First, include some null records:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'# Create some missing data\ndf = df.with_columns(\n    pl.when(pl.col("age") > 68)\n    .then(None)\n    .otherwise(pl.col("bmi"))\n    .alias("bmi")\n)\n'})}),"\n",(0,t.jsxs)(n.p,{children:["With the code above, we\u2019ve created a situation where whenever ",(0,t.jsx)(n.code,{children:"age"})," is over 68, corresponding ",(0,t.jsx)(n.code,{children:"bmi"})," becomes null to simulate missing data. Let\u2019s see how Polars handles null values:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Finding Missing Values:"})," We can use ",(0,t.jsx)(n.code,{children:"df.null_count()"})," to see the total missing values for each column. A big advantage of Polars over pandas is that operations remain ",(0,t.jsx)(n.em,{children:"lazy"})," until evaluated and computations are vectorised with Apache Arrow, making operations such as this faster for large datasets!"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"shape: (1, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 age \u2506 city \u2506 is_married \u2506 bmi   \u2502\n\u2502 --- \u2506 ---  \u2506 ---        \u2506 ---   \u2502\n\u2502 u32 \u2506 u32  \u2506 u32        \u2506 u32   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0   \u2506 0    \u2506 0          \u2506 32143 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Imputing Missing Values:"})," For imputing missing values in the ",(0,t.jsx)(n.code,{children:"bmi"})," column, we can use the following command. It replaces any occurrence of null with the ",(0,t.jsx)(n.em,{children:"median"})," of the column ",(0,t.jsx)(n.code,{children:"bmi"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'df = df.with_columns(pl.col("bmi").fill_null(pl.median("bmi")))\n'})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Dropping Missing Values:"})," If we want to remove all rows with missing values, we may do so using ",(0,t.jsx)(n.code,{children:"df.drop_nulls()"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"data-type-conversion",children:"Data Type Conversion"}),"\n",(0,t.jsx)(n.p,{children:"Converting data types is a common necessity in preprocessing. Polars provides an easy way to change the data type of a column:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'df.select(pl.col("bmi").cast(pl.Int32)).head()\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"shape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 bmi \u2502\n\u2502 --- \u2502\n\u2502 i32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 21  \u2502\n\u2502 24  \u2502\n\u2502 20  \u2502\n\u2502 24  \u2502\n\u2502 25  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The code above will convert ",(0,t.jsx)(n.code,{children:"bmi"})," column to integer data type."]}),"\n",(0,t.jsx)(n.h3,{id:"creating-new-columns",children:"Creating New Columns"}),"\n",(0,t.jsx)(n.p,{children:"Creating new features or columns based on existing ones could improve our analysis. With Polars, you can add a new column like so:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'df.with_columns((pl.col("age") * 12).alias("age_in_months")).head()\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"shape: (5, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 age \u2506 city     \u2506 is_married \u2506 bmi   \u2506 age_in_months \u2502\n\u2502 --- \u2506 ---      \u2506 ---        \u2506 ---   \u2506 ---           \u2502\n\u2502 i64 \u2506 str      \u2506 bool       \u2506 f64   \u2506 i64           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 24  \u2506 New York \u2506 true       \u2506 21.84 \u2506 288           \u2502\n\u2502 28  \u2506 Tokyo    \u2506 false      \u2506 24.37 \u2506 336           \u2502\n\u2502 27  \u2506 Tokyo    \u2506 false      \u2506 20.84 \u2506 324           \u2502\n\u2502 25  \u2506 London   \u2506 true       \u2506 24.02 \u2506 300           \u2502\n\u2502 26  \u2506 Paris    \u2506 true       \u2506 25.41 \u2506 312           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsxs)(n.p,{children:["This code generates a new column called ",(0,t.jsx)(n.code,{children:"age_in_months"})," which is ",(0,t.jsx)(n.code,{children:"age"})," column multiplied by 12."]}),"\n",(0,t.jsx)(n.h3,{id:"removing-duplicates",children:"Removing Duplicates"}),"\n",(0,t.jsxs)(n.p,{children:["Removing duplicate entries is crucial for maintaining accuracy. It\u2019s as simple as calling ",(0,t.jsx)(n.code,{children:"df.unique()"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:"df = df.unique()\n"})}),"\n",(0,t.jsx)(n.p,{children:"And voila, your data is clean and ready for some action! In the next section, we\u2019ll take a look at how to do data visualization. Keep following!"}),"\n",(0,t.jsx)(n.h2,{id:"data-visualization",children:"Data Visualization"}),"\n",(0,t.jsx)(n.p,{children:"While Polars does not have its own library for data visualization, it\u2019s fully compatible with popular Python libraries for creating plots and charts. We will use Matplotlib, that is one of the most popular libraries for creating data visualizations in Python."}),"\n",(0,t.jsx)(n.p,{children:"Now, let\u2019s create some visualizations for a sample of our synthetic dataset:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:"sample_df = df.sample(1000, seed=SEED)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"histogram",children:"Histogram"}),"\n",(0,t.jsxs)(n.p,{children:["To view the distribution of ",(0,t.jsx)(n.code,{children:"age"})," in our dataset, we would use a Histogram."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'# Create a figure\nplt.figure(figsize=(5, 4), layout="tight")\n\n# Plot\nplt.hist(sample_df["age"], bins=15, rwidth=0.9, color="dimgray")\n\n# Add a title and axis labels\nplt.title("Histogram of Ages")\nplt.xlabel("Age")\nplt.ylabel("Count")\n\n# Show the plot\nplt.show()\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:a(6260).Z+"",width:"486",height:"387"})}),"\n",(0,t.jsx)(n.h3,{id:"box-plot",children:"Box Plot"}),"\n",(0,t.jsx)(n.p,{children:"Box plots are great for visualizing the measure of dispersion and skewness in a dataset."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'# Create a figure\nplt.figure(figsize=(5, 2.2), layout="tight")\n\n# Plot\ncities_list = sample_df["city"].unique().sort().to_list()\n\nbplot = plt.boxplot(\n    [sample_df.filter(pl.col("city") == ct)["bmi"] for ct in cities_list],\n    notch=True,\n    labels=cities_list,\n    vert=False,\n    widths=0.5,\n    patch_artist=True,\n)\n\nfor i, color in enumerate(plt.cm.Dark2.colors[: len(cities_list)]):\n    bplot["boxes"][i].set(facecolor=color, alpha=0.9)\n    bplot["medians"][i].set(color="black")\n\n# Add a title and axis labels\nplt.title("Boxplot of BMIs by City")\nplt.xlabel("BMI")\n\n# Show the plot\nplt.show()\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:a(66547).Z+"",width:"486",height:"207"})}),"\n",(0,t.jsx)(n.h3,{id:"scatter-plot",children:"Scatter Plot"}),"\n",(0,t.jsxs)(n.p,{children:["Let\u2019s create a scatter plot to visualize the relationship between ",(0,t.jsx)(n.code,{children:"age"})," and ",(0,t.jsx)(n.code,{children:"bmi"})," in our dataset."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'# Create a figure\nplt.figure(figsize=(4, 4), layout="tight")\n\n# Plot\nplt.scatter(\n    sample_df["age"][:100], sample_df["bmi"][:100], color="deeppink", s=15\n)\n\n# Add a title and axis labels\nplt.title("Scatter Plot of BMI vs Age")\nplt.xlabel("Age")\nplt.ylabel("BMI")\n\n# Show the plot\nplt.show()\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:a(97994).Z+"",width:"386",height:"387"})}),"\n",(0,t.jsx)(n.h3,{id:"bar-chart",children:"Bar Chart"}),"\n",(0,t.jsxs)(n.p,{children:["To understand the distribution of ",(0,t.jsx)(n.code,{children:"age"})," data by ",(0,t.jsx)(n.code,{children:"city"}),", we can create a bar chart:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'# Create a figure\nplt.figure(figsize=(6, 4), layout="tight")\n\n# Plot\ngrouped_df = (\n    sample_df.group_by("city")\n    .agg(\n        pl.col("age").min().alias("min_age"),\n        pl.col("age").mean().alias("mean_age"),\n        pl.col("age").max().alias("max_age"),\n    )\n    .sort("city")\n)\n\ncities_list = grouped_df["city"].to_list()\n\nbar_width = 0.25\n_width = [-bar_width, 0, bar_width]\n_column = ["min_age", "mean_age", "max_age"]\n_label = ["Min", "Mean", "Max"]\n\nfor i, (width, column, label) in enumerate(zip(_width, _column, _label)):\n    plt.bar(\n        [x + width for x in range(len(cities_list))],\n        grouped_df[column],\n        width=bar_width,\n        label=label,\n        color=plt.cm.Set2.colors[i],\n    )\n\n# Add a title and axis labels\nplt.xticks(range(len(cities_list)), cities_list)\nplt.title("Bar Plot of Age by City")\nplt.ylabel("Age")\nplt.legend(loc="upper left")\n\n# Show the plot\nplt.show()\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:a(27957).Z+"",width:"586",height:"386"})}),"\n",(0,t.jsx)(n.p,{children:"These visuals should help illustrate insights in our dataset. As you can see, the integration of Polars with visual libraries such as Matplotlib makes exploratory data analysis a breeze. However, plots and visuals are just the tip of the Exploratory Data Analysis iceberg. Let\u2019s now move on to the next section where we discuss descriptive statistics and insights in more detail. Ready? Let\u2019s go!"}),"\n",(0,t.jsx)(n.h2,{id:"descriptive-statistics-and-insights",children:"Descriptive Statistics and Insights"}),"\n",(0,t.jsx)(n.p,{children:"Descriptive statistics reduce lots of data into simpler summaries, providing us with a comprehensive snapshot of our data. They describe the mass tendencies of our data and how they deviate from the norm."}),"\n",(0,t.jsx)(n.h3,{id:"mean",children:"Mean"}),"\n",(0,t.jsxs)(n.p,{children:["Let\u2019s start by calculating the mean of ",(0,t.jsx)(n.code,{children:"age"}),". The mean gives us the average value and is a good measure of the dataset\u2019s center."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'df["age"].mean()\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"43.34\n"})}),"\n",(0,t.jsx)(n.h3,{id:"median",children:"Median"}),"\n",(0,t.jsxs)(n.p,{children:["The median is the \u201cmiddle value\u201d or midpoint in your data and can be more informative than the mean when your data is ",(0,t.jsx)(n.em,{children:"skewed"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'df["age"].median()\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"43.0\n"})}),"\n",(0,t.jsx)(n.h3,{id:"standard-deviation",children:"Standard Deviation"}),"\n",(0,t.jsx)(n.p,{children:"The standard deviation tells us the spread of our data from the center, i.e., how much, on average, each value differs from the mean."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'df["age"].std()\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"14.20\n"})}),"\n",(0,t.jsx)(n.h3,{id:"correlation",children:"Correlation"}),"\n",(0,t.jsx)(n.p,{children:"Finally, one important aspect of data that we often look at in our exploratory data analysis is the correlation coefficient between variables."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'df.select(pl.corr("age", "bmi").alias("correlation"))\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"shape: (1, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 correlation \u2502\n\u2502 ---         \u2502\n\u2502 f64         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0.000631    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(n.p,{children:"The correlation coefficient measures the strength and direction of the linear relationship between the variables."}),"\n",(0,t.jsx)(n.p,{children:"We\u2019ve now unearthed the basics of Polars and its applications in data exploration. In the next section, we\u2019ll dive deeper into some advanced EDA techniques. Stick around!"}),"\n",(0,t.jsx)(n.h2,{id:"advanced-eda-techniques",children:"Advanced EDA Techniques"}),"\n",(0,t.jsx)(n.p,{children:"Polars enables us to go beyond basic descriptive statistics to implement a variety of advanced EDA techniques, facilitating comprehensive data investigations to generate deeper insights."}),"\n",(0,t.jsx)(n.h3,{id:"grouping-data",children:"Grouping Data"}),"\n",(0,t.jsx)(n.p,{children:"Group by operation helps to segment the data into groups, making it easier to analyze patterns across different categories."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'df.group_by("city").agg(\n    [\n        pl.col("age").mean().alias("average_age"),\n        pl.col("bmi").median().alias("median_bmi"),\n    ]\n)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"shape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 city     \u2506 average_age \u2506 median_bmi \u2502\n\u2502 ---      \u2506 ---         \u2506 ---        \u2502\n\u2502 str      \u2506 f64         \u2506 f64        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Paris    \u2506 42.299786   \u2506 22.0       \u2502\n\u2502 New York \u2506 43.479802   \u2506 22.0       \u2502\n\u2502 Tokyo    \u2506 43.775188   \u2506 22.0       \u2502\n\u2502 London   \u2506 43.368799   \u2506 22.01      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(n.p,{children:"Here we\u2019re examining the average age and median BMI for every city in our data."}),"\n",(0,t.jsx)(n.h3,{id:"apply-custom-functions",children:"Apply Custom Functions"}),"\n",(0,t.jsx)(n.p,{children:"With Polars you can apply your own custom functions to each value in the DataFrame\u2019s column."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'def age_group(age):\n    if age < 30:\n        return "Young"\n    elif age < 60:\n        return "Adult"\n    else:\n        return "Senior"\n\n\ndf.with_columns(\n    pl.col("age").map_elements(age_group).alias("age_group")\n).head()\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"shape: (5, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 age \u2506 city     \u2506 is_married \u2506 bmi   \u2506 age_group \u2502\n\u2502 --- \u2506 ---      \u2506 ---        \u2506 ---   \u2506 ---       \u2502\n\u2502 i64 \u2506 str      \u2506 bool       \u2506 f64   \u2506 str       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 28  \u2506 Tokyo    \u2506 false      \u2506 24.37 \u2506 Young     \u2502\n\u2502 35  \u2506 Paris    \u2506 false      \u2506 24.47 \u2506 Adult     \u2502\n\u2502 33  \u2506 Tokyo    \u2506 true       \u2506 19.55 \u2506 Adult     \u2502\n\u2502 26  \u2506 Tokyo    \u2506 false      \u2506 19.3  \u2506 Young     \u2502\n\u2502 24  \u2506 New York \u2506 true       \u2506 23.99 \u2506 Young     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(n.p,{children:"Here, we have built a new categorical variable indicating the age group of each individual."}),"\n",(0,t.jsx)(n.h3,{id:"pivot-tables",children:"Pivot Tables"}),"\n",(0,t.jsx)(n.p,{children:"Pivot tables can be used to restructure the data, which can provide us with a different perspective of our data."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Python"',children:'df.pivot(\n    index="is_married",\n    columns="city",\n    values="bmi",\n    aggregate_function="mean",\n)\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"shape: (2, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 is_married \u2506 Tokyo     \u2506 Paris     \u2506 New York  \u2506 London    \u2502\n\u2502 ---        \u2506 ---       \u2506 ---       \u2506 ---       \u2506 ---       \u2502\n\u2502 bool       \u2506 f64       \u2506 f64       \u2506 f64       \u2506 f64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 false      \u2506 21.999371 \u2506 21.985739 \u2506 22.002251 \u2506 22.001244 \u2502\n\u2502 true       \u2506 21.999968 \u2506 22.019422 \u2506 21.992436 \u2506 22.003721 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(n.p,{children:"In this case, we have created a pivot table to inspect the average BMI for each city and for groups of married and not married individuals."}),"\n",(0,t.jsx)(n.p,{children:"Employing advanced EDA techniques allows us to understand the data from different perspectives, enabling us to extract in-depth actionable insights from our data."}),"\n",(0,t.jsx)(n.p,{children:"Let\u2019s now draw the curtains by discussing some conclusions and next steps in the last section."}),"\n",(0,t.jsx)(n.h2,{id:"conclusion-and-next-steps",children:"Conclusion and Next Steps"}),"\n",(0,t.jsx)(n.p,{children:"Our journey so far has been enriching, and we have explored numerous facets of the versatile Polars library. From setting up the environment to performing Exploratory Data Analysis (EDA), Polars has proven to be an impeccable ally at every step."}),"\n",(0,t.jsx)(n.p,{children:"The simplicity of its API, coupled with its unrivalled performance with large datasets, makes Polars a library to watch out for in large data handling in Python. As we have seen, Polars brings together the best of both worlds, by offering the ease of using Pandas or Spark and the performance of data-centric languages like Rust and Apache Arrow and does so beautifully."}),"\n",(0,t.jsx)(n.p,{children:"However, as is true with all journeys, our exploration doesn\u2019t end here. Here are some fruitful directions that you can venture into in your next steps with Polars:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Dive deeper into library\u2019s documentation to explore more functions and capabilities."}),"\n",(0,t.jsx)(n.li,{children:"Employ Polars to your existing data science projects and witness the change in performance."}),"\n",(0,t.jsx)(n.li,{children:"Explore the interoperability of Polars with various Machine Learning Libraries."}),"\n",(0,t.jsx)(n.li,{children:"Participate in kaggle competitions using Polars and see where you stand."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The nexus of data science is evolving, and Polars is one such gem that\u2019s adding a vibrant hue to this landscape. The library is continually being improved and updated, and many new features and enhancements are in the pipeline."}),"\n",(0,t.jsxs)(n.p,{children:["Always remember, in data science, the ",(0,t.jsx)(n.em,{children:"greatest teacher is experience"}),". So, keep exploring and keep experimenting. And most importantly, enjoy the journey as much as the destination. After all, that\u2019s what exploratory data analysis is all about!"]}),"\n",(0,t.jsx)(n.p,{children:"Happy analyzing with Polars!"})]})}function h(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},27957:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/polars-bar-a21377be1145f94915de4405da612bf6.png"},66547:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/polars-box-8f66b7d9f802daecea19efdf4dc68502.png"},6260:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/polars-hist-01b557642db3266dffb33ef8c8905170.png"},97994:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/polars-scatter-7b02982294b4a4ff31a8e638a7810e8d.png"},11151:(e,n,a)=>{a.d(n,{Z:()=>r,a:()=>l});var t=a(67294);const i={},s=t.createContext(i);function l(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);