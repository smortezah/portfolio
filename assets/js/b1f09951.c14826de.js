"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[7975],{3905:(e,r,t)=>{t.d(r,{Zo:()=>h,kt:()=>m});var a=t(7294);function o(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function n(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);r&&(a=a.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,a)}return t}function i(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?n(Object(t),!0).forEach((function(r){o(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):n(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function l(e,r){if(null==e)return{};var t,a,o=function(e,r){if(null==e)return{};var t,a,o={},n=Object.keys(e);for(a=0;a<n.length;a++)t=n[a],r.indexOf(t)>=0||(o[t]=e[t]);return o}(e,r);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(a=0;a<n.length;a++)t=n[a],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var s=a.createContext({}),c=function(e){var r=a.useContext(s),t=r;return e&&(t="function"==typeof e?e(r):i(i({},r),e)),t},h=function(e){var r=c(e.components);return a.createElement(s.Provider,{value:r},e.children)},u="mdxType",p={inlineCode:"code",wrapper:function(e){var r=e.children;return a.createElement(a.Fragment,{},r)}},f=a.forwardRef((function(e,r){var t=e.components,o=e.mdxType,n=e.originalType,s=e.parentName,h=l(e,["components","mdxType","originalType","parentName"]),u=c(t),f=o,m=u["".concat(s,".").concat(f)]||u[f]||p[f]||n;return t?a.createElement(m,i(i({ref:r},h),{},{components:t})):a.createElement(m,i({ref:r},h))}));function m(e,r){var t=arguments,o=r&&r.mdxType;if("string"==typeof e||o){var n=t.length,i=new Array(n);i[0]=f;var l={};for(var s in r)hasOwnProperty.call(r,s)&&(l[s]=r[s]);l.originalType=e,l[u]="string"==typeof e?e:o,i[1]=l;for(var c=2;c<n;c++)i[c]=t[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,t)}f.displayName="MDXCreateElement"},3793:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>s,contentTitle:()=>i,default:()=>p,frontMatter:()=>n,metadata:()=>l,toc:()=>c});var a=t(7462),o=(t(7294),t(3905));const n={title:"Keras Core",authors:["mori"],tags:["Keras","PyTorch","Jax","Deep Learning","Machine Learning"]},i="Introducing Keras Core",l={permalink:"/portfolio/blog/keras-core",source:"@site/blog/keras-core.md",title:"Keras Core",description:"Hey there, data enthusiasts! Get ready to witness the revolution in the world of deep learning frameworks with the arrival of Keras Core, a preview version of the future of Keras. By Fall 2023, Keras Core will evolve into Keras 3.0, bringing remarkable advancements to the table. This groundbreaking library is a complete rewrite of the Keras codebase, establishing a modular backend architecture. What does this mean for you? Well, it enables running Keras workflows on various frameworks, starting with TensorFlow, PyTorch, and JAX.",date:"2023-10-11T08:54:50.000Z",formattedDate:"October 11, 2023",tags:[{label:"Keras",permalink:"/portfolio/blog/tags/keras"},{label:"PyTorch",permalink:"/portfolio/blog/tags/py-torch"},{label:"Jax",permalink:"/portfolio/blog/tags/jax"},{label:"Deep Learning",permalink:"/portfolio/blog/tags/deep-learning"},{label:"Machine Learning",permalink:"/portfolio/blog/tags/machine-learning"}],readingTime:4.32,hasTruncateMarker:!0,authors:[{name:"Morteza Hosseini",title:"Data scientist / ML engineer",key:"mori"}],frontMatter:{title:"Keras Core",authors:["mori"],tags:["Keras","PyTorch","Jax","Deep Learning","Machine Learning"]},prevItem:{title:"AI Ethics",permalink:"/portfolio/blog/ethics"}},s={authorsImageUrls:[void 0]},c=[{value:"Why Use Keras Core?",id:"why-use-keras-core",level:2}],h={toc:c},u="wrapper";function p(e){let{components:r,...t}=e;return(0,o.kt)(u,(0,a.Z)({},h,t,{components:r,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Hey there, data enthusiasts! Get ready to witness the revolution in the world of deep learning frameworks with the arrival of Keras Core, a preview version of the future of Keras. By Fall 2023, Keras Core will evolve into Keras 3.0, bringing remarkable advancements to the table. This groundbreaking library is a complete rewrite of the Keras codebase, establishing a modular backend architecture. What does this mean for you? Well, it enables running Keras workflows on various frameworks, starting with TensorFlow, PyTorch, and JAX."),(0,o.kt)("p",null,"Exciting times lie ahead!"),(0,o.kt)("h2",{id:"why-use-keras-core"},"Why Use Keras Core?"),(0,o.kt)("p",null,"But wait, why are they making Keras multi-backend again? Let\u2019s take a quick trip down memory lane. Not too long ago, Keras had the ability to run on multiple backends like Theano, TensorFlow, CNTK, and even MXNet. However, in 2018, they decided to focus exclusively on TensorFlow as other backends discontinued development. But times have changed! Fast forward to 2023, and we see TensorFlow dominating the production ML space with a market share of 55% to 60%. On the other hand, PyTorch has captured the ML research realm with a market share of 40% to 45%. Meanwhile, JAX, although with a smaller market share, has gained recognition from leading players in generative AI. It\u2019s clear that each framework has its strengths and user base. Keras Core enables the users to leverage the power of all three frameworks simultaneously."),(0,o.kt)("p",null,"Say goodbye to framework silos and welcome the new era of multi-framework ML!"))}p.isMDXComponent=!0}}]);