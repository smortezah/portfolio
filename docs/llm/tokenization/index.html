<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-llm/tokenization" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0">
<title data-rh="true">Tokenization | Portfolio</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://smortezah.github.io/portfolio/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://smortezah.github.io/portfolio/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://smortezah.github.io/portfolio/docs/llm/tokenization"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Tokenization | Portfolio"><meta data-rh="true" name="description" content="Explore tokenization techniques"><meta data-rh="true" property="og:description" content="Explore tokenization techniques"><link data-rh="true" rel="icon" href="/portfolio/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://smortezah.github.io/portfolio/docs/llm/tokenization"><link data-rh="true" rel="alternate" href="https://smortezah.github.io/portfolio/docs/llm/tokenization" hreflang="en"><link data-rh="true" rel="alternate" href="https://smortezah.github.io/portfolio/docs/llm/tokenization" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://MZL4UESJDY-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/portfolio/blog/rss.xml" title="Portfolio RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/portfolio/blog/atom.xml" title="Portfolio Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="Portfolio" href="/portfolio/opensearch.xml">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/portfolio/assets/css/styles.5107866c.css">
<script src="/portfolio/assets/js/runtime~main.b343b7af.js" defer="defer"></script>
<script src="/portfolio/assets/js/main.2e5ff559.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/portfolio/"><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/portfolio/docs">Tutorials</a><a class="navbar__item navbar__link" href="/portfolio/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/smortezah/portfolio" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/portfolio/docs/">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/anomaly-detection/">Anomaly Detection</a><button aria-label="Expand sidebar category &#x27;Anomaly Detection&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/automation/">Automation</a><button aria-label="Expand sidebar category &#x27;Automation&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/best-practices/">Best Practices</a><button aria-label="Expand sidebar category &#x27;Best Practices&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/computer-vision/">Computer Vision</a><button aria-label="Expand sidebar category &#x27;Computer Vision&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/data-structure/">Data Structures</a><button aria-label="Expand sidebar category &#x27;Data Structures&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/eda/">Exploratory Data Analysis</a><button aria-label="Expand sidebar category &#x27;Exploratory Data Analysis&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/etl/">Extract, Transform, Load</a><button aria-label="Expand sidebar category &#x27;Extract, Transform, Load&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/format/">Data Format</a><button aria-label="Expand sidebar category &#x27;Data Format&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/hypertune/">Hyperparameter Tuning</a><button aria-label="Expand sidebar category &#x27;Hyperparameter Tuning&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/portfolio/docs/llm/">Large Language Model (LLM)</a><button aria-label="Collapse sidebar category &#x27;Large Language Model (LLM)&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/portfolio/docs/llm/tokenization">Tokenization</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/machine-learning/">Machine learning</a><button aria-label="Expand sidebar category &#x27;Machine learning&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/privacy/">Data Privacy</a><button aria-label="Expand sidebar category &#x27;Data Privacy&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/python/">Python</a><button aria-label="Expand sidebar category &#x27;Python&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/scrape/">Web Scraping</a><button aria-label="Expand sidebar category &#x27;Web Scraping&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/stats/">Statistics</a><button aria-label="Expand sidebar category &#x27;Statistics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/synthetic-data/">Synthetic Data</a><button aria-label="Expand sidebar category &#x27;Synthetic Data&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/terminal/">Terminal</a><button aria-label="Expand sidebar category &#x27;Terminal&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/time-series/">Time Series</a><button aria-label="Expand sidebar category &#x27;Time Series&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/visualization/">Data Visualization</a><button aria-label="Expand sidebar category &#x27;Data Visualization&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/portfolio/docs/xai/">Explainable AI</a><button aria-label="Expand sidebar category &#x27;Explainable AI&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/portfolio/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/portfolio/docs/llm/"><span itemprop="name">Large Language Model (LLM)</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Tokenization</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Tokenization</h1>
<p><img loading="lazy" alt="OpenAI tokenizer" src="/portfolio/assets/images/token-bpe-a00bf16751815a631f878e4c059f161f.png" width="1434" height="470" class="img_ev3q"></p>
<p>Tokenization is a crucial step in natural language processing (NLP), where we break down text into smaller units (tokens) for further analysis. In this article, we’ll explore various tokenization techniques, their pros and cons, and practical tips for implementing them in Python.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-introduction-to-tokenization">1. Introduction to Tokenization<a href="#1-introduction-to-tokenization" class="hash-link" aria-label="Direct link to 1. Introduction to Tokenization" title="Direct link to 1. Introduction to Tokenization">​</a></h2>
<p>In this section, we&#x27;ll explore the basics of tokenization, its importance for large language models (LLMs), and the difference between tokenization and word segmentation.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-tokenization">What is Tokenization?<a href="#what-is-tokenization" class="hash-link" aria-label="Direct link to What is Tokenization?" title="Direct link to What is Tokenization?">​</a></h3>
<p>Tokenization is the process of breaking down a piece of text (usually a sentence or a document) into smaller units called <strong>tokens</strong>. These tokens can be words, subwords, or even characters. Why do we need tokenization? Well, imagine trying to analyze a long paragraph without breaking it down into meaningful chunks-it would be like trying to solve a jigsaw puzzle blindfolded!</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-is-tokenization-essential-for-llms">Why is Tokenization Essential for LLMs?<a href="#why-is-tokenization-essential-for-llms" class="hash-link" aria-label="Direct link to Why is Tokenization Essential for LLMs?" title="Direct link to Why is Tokenization Essential for LLMs?">​</a></h3>
<p>Large language models, such as BERT, GPT, and their variants, rely heavily on tokenization. Here&#x27;s why:</p>
<ol>
<li>
<p><strong>Input Representation</strong>: LLMs process input text in the form of tokenized sequences. Each token corresponds to a position in the input.</p>
</li>
<li>
<p><strong>Fixed-Length Context</strong>: LLMs have a fixed context window (e.g., 512 tokens for BERT). Tokenization ensures that the input fits within this window.</p>
</li>
<li>
<p><strong>Embeddings</strong>: Tokens are converted into dense vector representations (embeddings) that capture semantic meaning. These embeddings drive the model&#x27;s predictions.</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tokenization-vs-word-segmentation">Tokenization vs. Word Segmentation<a href="#tokenization-vs-word-segmentation" class="hash-link" aria-label="Direct link to Tokenization vs. Word Segmentation" title="Direct link to Tokenization vs. Word Segmentation">​</a></h3>
<p>While tokenization and word segmentation might seem similar, they serve different purposes:</p>
<ol>
<li>
<p><strong>Tokenization</strong>: Focuses on dividing text into meaningful units (tokens). It handles punctuation, special characters, and spaces.</p>
</li>
<li>
<p><strong>Word Segmentation</strong>: Specifically deals with splitting languages like Chinese or Japanese, where words don&#x27;t have clear spaces. Word segmentation breaks down continuous text into individual words.</p>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-basic-tokenization-techniques">2. Basic Tokenization Techniques<a href="#2-basic-tokenization-techniques" class="hash-link" aria-label="Direct link to 2. Basic Tokenization Techniques" title="Direct link to 2. Basic Tokenization Techniques">​</a></h2>
<p>In this section, we&#x27;ll explore the fundamental tokenization techniques that form the building blocks for more advanced methods.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sentence-tokenization">Sentence Tokenization<a href="#sentence-tokenization" class="hash-link" aria-label="Direct link to Sentence Tokenization" title="Direct link to Sentence Tokenization">​</a></h3>
<p><strong>Sentence tokenization</strong> involves splitting a text into individual sentences. It&#x27;s essential because many NLP tasks operate at the sentence level. Python&#x27;s <code>nltk</code> library provides useful tools for sentence tokenization:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> nltk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> nltk</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tokenize </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> sent_tokenize</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">nltk</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">download</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&#x27;punkt&#x27;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Tokenization is fascinating. Sentence tokenization splits text into sentences. It&#x27;s crucial for NLP.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentences </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> sent_tokenize</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">text</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> sentence </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> sentences</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sentence</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Output:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Tokenization is fascinating.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Sentence tokenization splits text into sentences.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">It&#x27;s crucial for NLP.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="word-tokenization">Word Tokenization<a href="#word-tokenization" class="hash-link" aria-label="Direct link to Word Tokenization" title="Direct link to Word Tokenization">​</a></h3>
<p><strong>Word tokenization</strong> breaks down a sentence into individual words. The <code>nltk</code> library also offers word tokenization:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> nltk</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tokenize </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> word_tokenize</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentence </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Word tokenization is essential for NLP tasks.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">words </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> word_tokenize</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sentence</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">words</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Output:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[&#x27;Word&#x27;, &#x27;tokenization&#x27;, &#x27;is&#x27;, &#x27;essential&#x27;, &#x27;for&#x27;, &#x27;NLP&#x27;, &#x27;tasks&#x27;, &#x27;.&#x27;]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="subword-tokenization-eg-byte-pair-encoding">Subword Tokenization (e.g., Byte-Pair Encoding)<a href="#subword-tokenization-eg-byte-pair-encoding" class="hash-link" aria-label="Direct link to Subword Tokenization (e.g., Byte-Pair Encoding)" title="Direct link to Subword Tokenization (e.g., Byte-Pair Encoding)">​</a></h3>
<p>Subword tokenization splits text into smaller units, such as subwords or characters. <strong>Byte-Pair Encoding (BPE)</strong> is a popular subword tokenization method. It merges the most frequent character pairs iteratively to create subword tokens. The <code>tiktoken</code> library in Python provides an efficient BPE implementation:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> tiktoken</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">enc </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> tiktoken</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">get_encoding</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;cl100k_base&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">text </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Subword tokenization with BPE is powerful.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">encoded </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> enc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">encode</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">text</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">decoded </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> enc</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">decode</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">encoded</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">assert</span><span class="token plain"> decoded </span><span class="token operator" style="color:#393A34">==</span><span class="token plain"> text</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">encoded</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Output:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[3214, 1178, 4037, 2065, 449, 426, 1777, 374, 8147, 13]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-advanced-tokenization-methods">3. Advanced Tokenization Methods<a href="#3-advanced-tokenization-methods" class="hash-link" aria-label="Direct link to 3. Advanced Tokenization Methods" title="Direct link to 3. Advanced Tokenization Methods">​</a></h2>
<p>In this segment, we&#x27;ll explore more sophisticated tokenization techniques that go beyond the basics. Let&#x27;s dive right in!</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="byte-level-bpe-byte-pair-encoding">Byte-Level BPE (Byte-Pair Encoding)<a href="#byte-level-bpe-byte-pair-encoding" class="hash-link" aria-label="Direct link to Byte-Level BPE (Byte-Pair Encoding)" title="Direct link to Byte-Level BPE (Byte-Pair Encoding)">​</a></h3>
<p><strong>Byte-Level BPE</strong> is a powerful subword tokenization method. It operates at the byte level, making it suitable for handling various languages, special characters, and emojis. Here&#x27;s how it works:</p>
<ol>
<li>
<p><strong>Learn Subword Vocabulary</strong>: Byte-Level BPE starts with a vocabulary containing individual bytes (characters). It then iteratively merges the most frequent byte pairs until reaching a specified vocabulary size.</p>
</li>
<li>
<p><strong>Subword Encoding</strong>: Given a text, Byte-Level BPE encodes it by replacing common byte pairs with subword tokens. For example, the word &quot;unhappiness&quot; might be encoded as &quot;un##happiness.&quot;</p>
</li>
<li>
<p><strong>Decoding</strong>: During decoding, we reverse the process to obtain the original text.</p>
</li>
</ol>
<p>Let&#x27;s see an example using Python and the <code>tokenizers</code> library:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> tokenizers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Tokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Tokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;bert-base-uncased&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">encoded </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">encode</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;Byte-Level BPE is fascinating.&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">decoded </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">decode</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">encoded</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">ids</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">encoded</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tokens</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Output:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">[&#x27;[CLS]&#x27;, &#x27;byte&#x27;, &#x27;-&#x27;, &#x27;level&#x27;, &#x27;bp&#x27;, &#x27;##e&#x27;, &#x27;is&#x27;, &#x27;fascinating&#x27;, &#x27;.&#x27;, &#x27;[SEP]&#x27;]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sentencepiece">SentencePiece<a href="#sentencepiece" class="hash-link" aria-label="Direct link to SentencePiece" title="Direct link to SentencePiece">​</a></h3>
<p><strong>SentencePiece</strong> is another subword tokenization method that&#x27;s widely used in NLP. It&#x27;s particularly effective for languages with complex word boundaries (e.g., Japanese, Korean). Here&#x27;s how it works:</p>
<ol>
<li>
<p><strong>Unsupervised Learning</strong>: SentencePiece learns subword units from raw text without relying on word boundaries or linguistic knowledge.</p>
</li>
<li>
<p><strong>Vocabulary Size</strong>: You can control the vocabulary size, allowing flexibility in balancing token granularity.</p>
</li>
<li>
<p><strong>Subword Encoding and Decoding</strong>: Similar to BPE, SentencePiece encodes and decodes text efficiently.</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="unigram-language-model">Unigram Language Model<a href="#unigram-language-model" class="hash-link" aria-label="Direct link to Unigram Language Model" title="Direct link to Unigram Language Model">​</a></h3>
<p>The <strong>Unigram Language Model</strong> tokenizes text based on the likelihood of each subword occurring independently. It doesn&#x27;t rely on pairs like BPE or SentencePiece. While less common, it&#x27;s worth exploring if you&#x27;re working with specific languages or domain-specific data.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-handling-special-cases">4. Handling Special Cases<a href="#4-handling-special-cases" class="hash-link" aria-label="Direct link to 4. Handling Special Cases" title="Direct link to 4. Handling Special Cases">​</a></h2>
<p>In this section, we&#x27;ll explore how to handle special cases during tokenization. While most tokenization methods work well for standard text, real-world data often contains challenges like emojis, URLs, and hashtags.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dealing-with-emojis-urls-and-hashtags">Dealing with Emojis, URLs, and Hashtags<a href="#dealing-with-emojis-urls-and-hashtags" class="hash-link" aria-label="Direct link to Dealing with Emojis, URLs, and Hashtags" title="Direct link to Dealing with Emojis, URLs, and Hashtags">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="emojis">Emojis<a href="#emojis" class="hash-link" aria-label="Direct link to Emojis" title="Direct link to Emojis">​</a></h4>
<p>Emojis add expressive power to text, but they can disrupt tokenization. Here&#x27;s how to handle them:</p>
<ol>
<li>
<p><strong>Preserve Emojis</strong>: Some tokenizers treat emojis as separate tokens. If you want to preserve them, ensure your tokenizer doesn&#x27;t split emojis into individual characters.</p>
</li>
<li>
<p><strong>Replace Emojis</strong>: Alternatively, you can replace emojis with a special token (e.g., <code>&lt;EMOJI&gt;</code>). This simplifies tokenization.</p>
</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="urls">URLs<a href="#urls" class="hash-link" aria-label="Direct link to URLs" title="Direct link to URLs">​</a></h4>
<p>URLs contain special characters (e.g., slashes, dots) that can confuse tokenizers. Consider the following approaches:</p>
<ol>
<li>
<p><strong>Remove URLs</strong>: If URLs don&#x27;t carry essential information, remove them before tokenization.</p>
</li>
<li>
<p><strong>Replace URLs</strong>: Replace URLs with a placeholder (e.g., <code>&lt;URL&gt;</code>). This ensures they don&#x27;t interfere with token boundaries.</p>
</li>
</ol>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="hashtags">Hashtags<a href="#hashtags" class="hash-link" aria-label="Direct link to Hashtags" title="Direct link to Hashtags">​</a></h4>
<p>Hashtags (common on social media) pose a similar challenge. Here&#x27;s how to handle them:</p>
<ol>
<li>
<p><strong>Split Hashtags</strong>: Split hashtags into individual words. For example, <code>#MachineLearning</code> becomes <code>Machine Learning</code>.</p>
</li>
<li>
<p><strong>Preserve Hashtags</strong>: If hashtags convey specific meaning, preserve them as a single token.</p>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="custom-tokenization-rules">Custom Tokenization Rules<a href="#custom-tokenization-rules" class="hash-link" aria-label="Direct link to Custom Tokenization Rules" title="Direct link to Custom Tokenization Rules">​</a></h3>
<p>Sometimes, you&#x27;ll encounter domain-specific terms or abbreviations. Custom rules can help:</p>
<ol>
<li>
<p><strong>Add Custom Tokens</strong>: Extend your tokenizer&#x27;s vocabulary with domain-specific terms. For instance, include medical abbreviations if working with healthcare data.</p>
</li>
<li>
<p><strong>Preprocess Text</strong>: Apply custom preprocessing (e.g., replacing acronyms) before tokenization.</p>
</li>
</ol>
<p>Adapt your approach based on your specific use case and the nature of your data.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-tokenization-in-pretrained-llms">5. Tokenization in Pretrained LLMs<a href="#5-tokenization-in-pretrained-llms" class="hash-link" aria-label="Direct link to 5. Tokenization in Pretrained LLMs" title="Direct link to 5. Tokenization in Pretrained LLMs">​</a></h2>
<p>In this section, we&#x27;ll explore how tokenization is handled in pretrained large language models (LLMs) like BERT, GPT, and their variants. These models have revolutionized NLP tasks, and understanding their tokenization process is essential for effective usage.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="how-bert-and-gpt-tokenize-input">How BERT and GPT Tokenize Input<a href="#how-bert-and-gpt-tokenize-input" class="hash-link" aria-label="Direct link to How BERT and GPT Tokenize Input" title="Direct link to How BERT and GPT Tokenize Input">​</a></h3>
<ol>
<li>
<p><strong>WordPiece Tokenization (BERT)</strong>:</p>
<ul>
<li>BERT uses <strong>WordPiece</strong> tokenization, which is similar to BPE but operates at the word level.</li>
<li>It starts with a vocabulary of subword units (usually words).</li>
<li>During tokenization, BERT splits words into subword tokens (e.g., &quot;unhappiness&quot; becomes &quot;un&quot; + &quot;##happiness&quot;).</li>
<li>Special tokens like <code>[CLS]</code> (classification) and <code>[SEP]</code> (separator) are added to the input.</li>
</ul>
</li>
<li>
<p><strong>Byte-Level Tokenization (GPT)</strong>:</p>
<ul>
<li>GPT models, on the other hand, use <strong>byte-level tokenization</strong>.</li>
<li>They treat each byte (character) as a token.</li>
<li>This approach handles languages with complex scripts (e.g., Chinese, Japanese) effectively.</li>
</ul>
</li>
<li>
<p><strong>Special Tokens</strong>:</p>
<ul>
<li>Both BERT and GPT add special tokens to the input sequence.</li>
<li><code>[CLS]</code> token marks the start of the input, and <code>[SEP]</code> token separates segments (e.g., sentences or paragraphs).</li>
<li>Positional embeddings ensure the model understands token order.</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="practical-example">Practical Example<a href="#practical-example" class="hash-link" aria-label="Direct link to Practical Example" title="Direct link to Practical Example">​</a></h3>
<p>Let&#x27;s see how to tokenize a sentence using the popular <code>transformers</code> library in Python:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockTitle_Ktv7">Python</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> BertTokenizer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> GPT2Tokenizer</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load BERT and GPT2 tokenizers</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bert_tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> BertTokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;bert-base-uncased&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gpt2_tokenizer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> GPT2Tokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;gpt2&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Tokenize a sentence</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">sentence </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Tokenization is fascinating.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bert_tokens </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> bert_tokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tokenize</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sentence</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">gpt2_tokens </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> gpt2_tokenizer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">tokenize</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">sentence</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;BERT tokens:&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> bert_tokens</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;GPT-2 tokens:&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> gpt2_tokens</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Output:</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">BERT tokens: [&#x27;token&#x27;, &#x27;##ization&#x27;, &#x27;is&#x27;, &#x27;fascinating&#x27;, &#x27;.&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">GPT-2 tokens: [&#x27;Token&#x27;, &#x27;ization&#x27;, &#x27;Ġis&#x27;, &#x27;Ġfascinating&#x27;, &#x27;.&#x27;]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="special-considerations">Special Considerations:<a href="#special-considerations" class="hash-link" aria-label="Direct link to Special Considerations:" title="Direct link to Special Considerations:">​</a></h3>
<ul>
<li><strong>Subword Units</strong>: BERT and GPT handle subword units differently, impacting their tokenization behavior.</li>
<li><strong>Custom Tokens</strong>: You can add custom tokens to the vocabulary for domain-specific tasks.</li>
</ul>
<p>Remember that tokenization affects downstream tasks, so choose the right method based on your use case.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-tips-for-efficient-tokenization">6. Tips for Efficient Tokenization<a href="#6-tips-for-efficient-tokenization" class="hash-link" aria-label="Direct link to 6. Tips for Efficient Tokenization" title="Direct link to 6. Tips for Efficient Tokenization">​</a></h2>
<p>Tokenization is a critical step in natural language processing (NLP), and optimizing this process can significantly impact your overall workflow. Here are some practical tips to ensure efficient tokenization:</p>
<ol>
<li>
<p><strong>Batch Processing</strong>:</p>
<ul>
<li>If you&#x27;re dealing with a large dataset, consider batch processing. Tokenize multiple sentences at once to reduce overhead and improve speed.</li>
<li>Libraries like <code>transformers</code> allow batch tokenization, which is especially useful when working with pretrained language models.</li>
</ul>
</li>
<li>
<p><strong>Preprocessing</strong>:</p>
<ul>
<li>Clean your text before tokenization. Remove unnecessary characters, HTML tags, or special symbols.</li>
<li>Address common issues like extra spaces, line breaks, and punctuation.</li>
</ul>
</li>
<li>
<p><strong>Custom Rules</strong>:</p>
<ul>
<li>Add custom rules to handle domain-specific terms or special cases.</li>
<li>For instance, if you&#x27;re working with medical data, include medical abbreviations in your tokenizer&#x27;s vocabulary.</li>
</ul>
</li>
</ol>
<p>And there you have it! Armed with these practical examples, you&#x27;re ready to tokenize text like a pro. If you have any questions or need further assistance, feel free to ask!</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/portfolio/docs/tags/tokenization">tokenization</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/portfolio/docs/tags/llm">LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/portfolio/docs/tags/nlp">NLP</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/portfolio/docs/tags/python">python</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/portfolio/docs/tags/ai">AI</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/portfolio/docs/llm/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Large Language Model (LLM)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/portfolio/docs/machine-learning/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Machine learning</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-introduction-to-tokenization" class="table-of-contents__link toc-highlight">1. Introduction to Tokenization</a><ul><li><a href="#what-is-tokenization" class="table-of-contents__link toc-highlight">What is Tokenization?</a></li><li><a href="#why-is-tokenization-essential-for-llms" class="table-of-contents__link toc-highlight">Why is Tokenization Essential for LLMs?</a></li><li><a href="#tokenization-vs-word-segmentation" class="table-of-contents__link toc-highlight">Tokenization vs. Word Segmentation</a></li></ul></li><li><a href="#2-basic-tokenization-techniques" class="table-of-contents__link toc-highlight">2. Basic Tokenization Techniques</a><ul><li><a href="#sentence-tokenization" class="table-of-contents__link toc-highlight">Sentence Tokenization</a></li><li><a href="#word-tokenization" class="table-of-contents__link toc-highlight">Word Tokenization</a></li><li><a href="#subword-tokenization-eg-byte-pair-encoding" class="table-of-contents__link toc-highlight">Subword Tokenization (e.g., Byte-Pair Encoding)</a></li></ul></li><li><a href="#3-advanced-tokenization-methods" class="table-of-contents__link toc-highlight">3. Advanced Tokenization Methods</a><ul><li><a href="#byte-level-bpe-byte-pair-encoding" class="table-of-contents__link toc-highlight">Byte-Level BPE (Byte-Pair Encoding)</a></li><li><a href="#sentencepiece" class="table-of-contents__link toc-highlight">SentencePiece</a></li><li><a href="#unigram-language-model" class="table-of-contents__link toc-highlight">Unigram Language Model</a></li></ul></li><li><a href="#4-handling-special-cases" class="table-of-contents__link toc-highlight">4. Handling Special Cases</a><ul><li><a href="#dealing-with-emojis-urls-and-hashtags" class="table-of-contents__link toc-highlight">Dealing with Emojis, URLs, and Hashtags</a></li><li><a href="#custom-tokenization-rules" class="table-of-contents__link toc-highlight">Custom Tokenization Rules</a></li></ul></li><li><a href="#5-tokenization-in-pretrained-llms" class="table-of-contents__link toc-highlight">5. Tokenization in Pretrained LLMs</a><ul><li><a href="#how-bert-and-gpt-tokenize-input" class="table-of-contents__link toc-highlight">How BERT and GPT Tokenize Input</a></li><li><a href="#practical-example" class="table-of-contents__link toc-highlight">Practical Example</a></li><li><a href="#special-considerations" class="table-of-contents__link toc-highlight">Special Considerations:</a></li></ul></li><li><a href="#6-tips-for-efficient-tokenization" class="table-of-contents__link toc-highlight">6. Tips for Efficient Tokenization</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__links text--center"><div class="footer__links"><span class="footer__link-item">
              <a class="footer-medium-link" href="https://medium.com/@morihosseini" target="_blank" rel="noreferrer noopener" aria-label="Medium">
              </a>
            </span><span class="footer__link-separator">·</span><span class="footer__link-item">
              <a class="footer-github-link" href="https://github.com/smortezah" target="_blank" rel="noreferrer noopener" aria-label="GitHub">
              </a>
            </span><span class="footer__link-separator">·</span><span class="footer__link-item">
              <a class="footer-x-link" href="https://x.com/MoriHosseini1" target="_blank" rel="noreferrer noopener" aria-label="X">
              </a>
            </span><span class="footer__link-separator">·</span><span class="footer__link-item">
              <a class="footer-linkedin-link" href="https://linkedin.com/in/mori-hosseini" target="_blank" rel="noreferrer noopener" aria-label="LinkedIn">
              </a>
            </span></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright &copy; 2024 Morteza Hosseini</div></div></div></footer></div>
</body>
</html>